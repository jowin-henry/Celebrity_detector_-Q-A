
# ğŸ¬ Celebrity Detector & Q&A ğŸ¤–

This project combines state-of-the-art **Large Language Models (LLMs)** to deliver an intelligent celebrity recognition and question-answering web app.

## ğŸŒŸ Overview

The app leverages **vision transformer-powered LLMs** (specifically Metaâ€™s LLaMA 4 Scout 17B Instruct model hosted via Groq's API) to:

- ğŸ–¼ï¸ **Recognize celebrities** in user-uploaded images by analyzing visual input and generating structured textual information.
- ğŸ’¬ **Answer user questions** about the detected celebrity using natural language processing, providing concise, accurate, and context-aware responses.

## ğŸ“¸ Screenshots

Here are some example snapshots of the app in action:

### ğŸ” Celebrity Detection and Q&A

![Celebrity Detection Screenshot](images/ar.png)

### 
Ask questions and get concise, LLM-powered answers:
![Celebrity Q&A Screenshot](images/njr.png)



## ğŸš€ Key Features

- ğŸ¤ **Vision-Language Integration:** The model processes both image and text input by embedding the uploaded image in a prompt, allowing joint understanding.
- ğŸ­ **Celebrity Recognition:** The LLM identifies the person in the image and outputs detailed structured information (name, profession, nationality, achievements).
- â“ **Conversational Q&A:** Users can ask follow-up questions about the recognized celebrity, which the LLM answers using a tailored prompt to ensure accuracy and relevance.
- ğŸ‘ï¸â€ğŸ—¨ï¸ **Face Detection Preprocessing:** OpenCVâ€™s Haar cascade detects faces, focusing recognition on the largest face to improve LLM input quality.

## ğŸ—ï¸ Architecture

- ğŸŒ **Frontend:** A React/Flask web interface allows image upload and interaction.
- âš™ï¸ **Backend:**
  - `image_handler.py` preprocesses images and detects faces.
  - `celebrity_detector.py` sends images to the Groq API with the vision transformer LLM for celebrity identification.
  - `qa_engine.py` uses the same LLM to answer questions about the detected celebrity.
- ğŸ¤– **LLM Model:** Uses the `meta-llama/llama-4-maverick-17b-128e-instruct` model, a vision-capable transformer with strong NLP abilities, enabling multimodal understanding.

## ğŸ› ï¸ Installation & Setup

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/celebrity-detector-qa.git
   cd celebrity-detector-qa
   ```

2. Create a virtual environment and install dependencies:

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```
3. Add your Groq API key to a `.env` file:

   ```
   GROQ_API_KEY=your_api_key_here

   ```
4. Run the app:

   ```bash
   python app.py
   ```
5. Visit `http://localhost:5000` in your browser.

## ğŸ¯ Usage

* Upload an image containing a celebrityâ€™s face.
* The system detects and highlights the largest face.
* The vision transformer LLM processes the image and returns detailed information about the celebrity.
* Ask follow-up questions in natural language; the LLM answers them based on the celebrity context.

## ğŸ”§ Technologies

* ğŸ¤– **Large Language Model:** Meta LLaMA 4 Maverick 17B with vision capabilities
* â˜ï¸ **API Hosting:** Groq AI API for multimodal LLM inference
* ğŸ–¥ï¸ **Computer Vision:** OpenCV for face detection preprocessing
* ğŸ **Backend Framework:** Flask
* ğŸ¨ **Frontend Styling:** Tailwind CSS

## ğŸŒ± Future Improvements


* ğŸ‘¥ Add support for multiple faces per image with multi-identity recognition.
* ğŸ—£ï¸ Implement context-aware multi-turn conversational Q\&A.
* ğŸ›¡ï¸ Improve response safety and moderation in Q\&A.

---

