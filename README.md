
# ğŸ¬ Celebrity Detector & Q&A ğŸ¤–

This project combines state-of-the-art **Large Language Models (LLMs)** to deliver an intelligent celebrity recognition and question-answering web app.

## ğŸŒŸ Overview

The app leverages **vision transformer-powered LLMs** (specifically Metaâ€™s LLaMA 4 Scout 17B Instruct model hosted via Groq's API) to:

- ğŸ–¼ï¸ **Recognize celebrities** in user-uploaded images by analyzing visual input and generating structured textual information.
- ğŸ’¬ **Answer user questions** about the detected celebrity with concise, accurate, and context-aware responses.
- ğŸš€ **Use CI/CD pipelines** with CircleCI for automated testing, building, and deployment.
- â˜ï¸ **Deploy containerized app** on Google Cloud Platform (GCP) using Kubernetes via Google Kubernetes Engine (GKE).
- ğŸ›¡ï¸ **Enforce AI guardrails** to ensure safe, respectful, and privacy-preserving responses from the LLM.

## ğŸ“¸ Screenshots

Here are some example snapshots of the app in action:

### ğŸ” Celebrity Detection and Q&A

![Celebrity Detection Screenshot](images/ar.png)

### 
Ask questions and get concise, LLM-powered answers:
![Celebrity Q&A Screenshot](images/njr.png)



## ğŸš€ Key Features

- ğŸ¤ **Vision-Language Integration:** The model processes both image and text input by embedding the uploaded image in a prompt, allowing joint understanding.
- ğŸ­ **Celebrity Recognition:** The LLM identifies the person in the image and outputs detailed structured information (name, profession, nationality, achievements).
- â“ **Conversational Q&A:** Users can ask follow-up questions about the recognized celebrity, which the LLM answers using a tailored prompt to ensure accuracy and relevance.
- ğŸ‘ï¸â€ğŸ—¨ï¸ **Face Detection Preprocessing:** OpenCVâ€™s Haar cascade detects faces, focusing recognition on the largest face to improve LLM input quality.

## ğŸ—ï¸ Architecture

- ğŸŒ **Frontend:** A React/Flask web interface allows image upload and interaction.
- âš™ï¸ **Backend:**
  - `image_handler.py` preprocesses images and detects faces.
  - `celebrity_detector.py` sends images to the Groq API with the vision transformer LLM for celebrity identification.
  - `qa_engine.py` uses the same LLM to answer questions about the detected celebrity.
- ğŸ¤– **LLM Model:** Uses the `meta-llama/llama-4-maverick-17b-128e-instruct` model, a vision-capable transformer with strong NLP abilities, enabling multimodal understanding.

## ğŸ›¡ï¸ Guardrails for Safe and Respectful LLM Interaction

This project employs a custom **Guardrails XML specification** to control and validate the LLMâ€™s behavior during Q&A, ensuring:

- **Input Parameters:** The guardrail takes the celebrityâ€™s name and userâ€™s question as structured inputs.
- **Output Constraints:** The LLM must generate a concise, safe, and respectful answer to the userâ€™s question.
- **Response Instructions:**
  - Provide accurate and concise answers in full sentences.
  - Avoid private or unverified personal information.
  - Reject any questions requesting harmful, invasive, or disrespectful content.
  - Do not speculate on rumors or gossip.
- **Validation Rules:**
  - Output must conform to the expected schema.
  - Strict profanity filtering with re-prompting on failure.
  - Privacy filters block any mention of sensitive information such as phone numbers, addresses, emails, SSNs, etc.
  - Enforce a minimum length to ensure complete, informative sentences.
  
These guardrails help maintain **trust, safety, and quality** in user interactions by automatically enforcing ethical boundaries and factual correctness in all AI-generated responses.


## ğŸ› ï¸ Installation & Setup

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/celebrity-detector-qa.git
   cd celebrity-detector-qa
   ```

2. Create a virtual environment and install dependencies:

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```
3. Add your Groq API key to a `.env` file:

   ```
   GROQ_API_KEY=your_api_key_here

   ```
4. Run the app:

   ```bash
   python app.py
   ```
5. Visit `http://localhost:5000` in your browser.

## ğŸ¯ Usage

* Upload an image containing a celebrityâ€™s face.
* The system detects and highlights the largest face.
* The vision transformer LLM processes the image and returns detailed information about the celebrity.
* Ask follow-up questions in natural language; the LLM answers them based on the celebrity context.

Great â€” adding a **CI/CD & GCP deployment section** with your context will make your README much stronger and professional.
Hereâ€™s how you can integrate it into your README (Iâ€™ll keep the formatting and flow consistent with what you shared earlier):


## âš™ï¸ CI/CD & Deployment with CircleCI and GCP

This project is fully containerized and deployed on **Google Cloud Platform (GCP)** using **Google Kubernetes Engine (GKE)**, with continuous integration and delivery powered by **CircleCI**.

### âœ… Pre-Deployment Checklist

Make sure youâ€™ve completed the following:

1. âœ… Created a **Dockerfile**  
2. âœ… Written a **Kubernetes Deployment file**  
3. âœ… Set up **code versioning** on GitHub  

---

### âœ… Enable Required GCP APIs

In your GCP Console:

- Navigate to **APIs & Services â†’ Library**
- Enable:
  - Kubernetes Engine API  
  - Container Registry API  
  - Compute Engine API  
  - Cloud Build API  
  - Cloud Storage API  
  - IAM API  

---

### âœ… Create GKE Cluster and Artifact Registry

1. **GKE Cluster**
   - Search for **GKE** in the GCP Console
   - Create a new cluster (name of your choice)
   - Configure networking and access settings  

2. **Artifact Registry**
   - Search for **Artifact Registry**
   - Create a new registry for Docker images  

---

### âœ… Create a Service Account and Configure Access

1. Create a **Service Account** in GCP Console  
2. Assign these roles:
   - Storage Object Admin  
   - Storage Object Viewer  
   - Owner  
   - Artifact Registry Admin  
   - Artifact Registry Writer  
3. Download the key as `gcp-key.json`  
4. Place `gcp-key.json` in the root directory  
5. Add it to `.gitignore` to prevent accidental GitHub pushes  

---

### ğŸ” Convert `gcp-key.json` to Base64

Run in your terminal:

```bash
cat gcp-key.json | base64 -w 0
````

Save the output for CircleCI environment variables.

---

### âœ… Set Up CircleCI Configuration

1. Create `.circleci/config.yml` in your project root
2. Connect CircleCI to your GitHub repository
3. Configure **workflows and pipelines**
4. Add environment variables in CircleCI under **Project Settings â†’ Environment Variables**:

   * `GCLOUD_SERVICE_KEY` â€” Base64-encoded GCP key
   * `GOOGLE_PROJECT_ID` â€” your GCP project ID
   * `GKE_CLUSTER` â€” your cluster name
   * `GOOGLE_COMPUTE_REGION` â€” your region

---

### âœ… Set Up LLMOps Secrets in GKE

Use `kubectl` to create a Kubernetes secret for your Groq API key:

```bash
kubectl create secret generic llmops-secrets \
--from-literal=GROQ_API_KEY="your_actual_groq_api_key"
```

This ensures your application retrieves sensitive keys securely at runtime.

---

### âœ… Trigger CircleCI Pipeline

* Run the pipeline manually the first time in CircleCI to confirm setup.
* Afterward, each `git push` automatically triggers the pipeline to build, push, and deploy the app to GKE.

---

## ğŸ“¸ Deployment Snapshots

### ğŸš€ CircleCI Pipeline in Action

![CircleCI Pipeline Screenshot](images/Circleci.png)

### â˜ï¸ Google Kubernetes Engine (GKE) Cluster Deployment

![GKE Deployment](images/GKE2.png)

## Service Account setup
![Service_Account Screenshot](images/GKE2.png)



## ğŸ”§ Technologies used

- **Large Language Model:** Meta LLaMA 4 Scout 17B with vision capabilities  
- **API Hosting:** Groq AI API for multimodal LLM inference  
- **Computer Vision:** OpenCV for face detection preprocessing
- **CI/CD:** CircleCI for automated testing and deployment  
- **Cloud Deployment:** Google Cloud Platform (GKE & Artifact Registry)  
- **Containerization:** Docker and Kubernetes    
- **Backend Framework:** Flask  
- **Frontend Styling:** Tailwind CSS  




---

